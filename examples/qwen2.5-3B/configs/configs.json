{"sd_base_path":"/nas/services/huggingface/hub/models--Qwen--Qwen2.5-Coder-1.5B/snapshots/df3ce67c0e24480f20468b6ef2894622d69eb73b/model.safetensors","sd_merged_paths":{"plain":"/nas/services/huggingface/hub/models--Qwen--Qwen2.5-1.5B/snapshots/8faed761d45a263340a0528343f099c05c9a4323/model.safetensors"},"sd_output_path":"./out/merge_01","method":"abs_diff","seed_dict":{},"lambda_param":0.05,"sparsity":0.88,"use_ties":false,"weight_batch_size":96,"weight_batches_custom":[["model.embed_tokens.weight"]],"merge_device":"cuda"}
{"sd_base_path":"/nas/services/huggingface/hub/models--Qwen--Qwen2.5-Coder-1.5B/snapshots/df3ce67c0e24480f20468b6ef2894622d69eb73b/model.safetensors","sd_merged_paths":{"plain":"/nas/services/huggingface/hub/models--Qwen--Qwen2.5-1.5B/snapshots/8faed761d45a263340a0528343f099c05c9a4323/model.safetensors"},"sd_output_path":"./out/merge_02","method":"abs_diff","seed_dict":{},"lambda_param":0.05,"sparsity":0.9,"use_ties":false,"weight_batch_size":96,"weight_batches_custom":[["model.embed_tokens.weight"]],"merge_device":"cuda"}
{"sd_base_path":"/nas/services/huggingface/hub/models--Qwen--Qwen2.5-Coder-1.5B/snapshots/df3ce67c0e24480f20468b6ef2894622d69eb73b/model.safetensors","sd_merged_paths":{"plain":"/nas/services/huggingface/hub/models--Qwen--Qwen2.5-1.5B/snapshots/8faed761d45a263340a0528343f099c05c9a4323/model.safetensors"},"sd_output_path":"./out/merge_03","method":"abs_diff","seed_dict":{},"lambda_param":0.05,"sparsity":0.92,"use_ties":false,"weight_batch_size":96,"weight_batches_custom":[["model.embed_tokens.weight"]],"merge_device":"cuda"}
{"sd_base_path":"/nas/services/huggingface/hub/models--Qwen--Qwen2.5-1.5B/snapshots/8faed761d45a263340a0528343f099c05c9a4323/model.safetensors","sd_merged_paths":{"coder":"/nas/services/huggingface/hub/models--Qwen--Qwen2.5-Coder-1.5B/snapshots/df3ce67c0e24480f20468b6ef2894622d69eb73b/model.safetensors"},"sd_output_path":"./out/merge_04","method":"abs_diff","seed_dict":{},"lambda_param":0.05,"sparsity":0.92,"use_ties":false,"weight_batch_size":96,"weight_batches_custom":[["model.embed_tokens.weight"]],"merge_device":"cuda"}
